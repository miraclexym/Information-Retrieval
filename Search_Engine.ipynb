{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载倒排索引...\n",
      "倒排索引加载完成。\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import jieba\n",
    "import string\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "# 增加字段大小限制，设置为更大的值（比如 10MB）\n",
    "csv.field_size_limit(10000000)\n",
    "\n",
    "# 读取倒排索引\n",
    "def load_index(filename=\"index.pkl\"):\n",
    "    print(\"加载倒排索引...\")\n",
    "    with open(filename, 'rb') as f:\n",
    "        inverted_index, doc_tfs, idf = pickle.load(f)\n",
    "    print(\"倒排索引加载完成。\")\n",
    "    return inverted_index, doc_tfs, idf\n",
    "\n",
    "# 打开并读取 HtmlFile.csv 文件\n",
    "csv_filename = \"HtmlContent.csv\"\n",
    "\n",
    "# 读取文件中的内容\n",
    "with open(csv_filename, mode='r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    # 跳过表头（如果有的话）\n",
    "    next(csv_reader, None)\n",
    "    # 将所有内容读入列表\n",
    "    html_data = list(csv_reader)\n",
    "\n",
    "# 加载倒排索引\n",
    "inverted_index, doc_tfs, idf = load_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "正在搜索：南开大学ESI学科发展报告pdf\n",
      "搜索结果：\n",
      "网页标题: 南开大学ESI全球前1%学科增至15个 “微生物学”首次上榜-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2021/03/28/030045131.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\南开大学ESI全球前1%学科增至15个%20“微生物学”首次上榜-南开要闻-南开大学.html\n",
      "网页标题: 南开大学“社会科学总论”学科首次进入全球前1%-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2020/05/18/030039232.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\南开大学“社会科学总论”学科首次进入全球前1%-南开要闻-南开大学.html\n",
      "网页标题: 南开大学工程科学跻身ESI全球前1‰-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2023/11/25/030059003.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\南开大学工程科学跻身ESI全球前1‰-南开要闻-南开大学.html\n",
      "网页标题: 南开大学环境科学与生态学跻身ESI全球前1‰-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2024/07/17/030062633.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\南开大学环境科学与生态学跻身ESI全球前1‰-南开要闻-南开大学.html\n",
      "网页标题: 中央广电总台国际在线：南开大学环境科学与生态学跻身ESI全球前1‰-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2024/07/18/030062653.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\中央广电总台国际在线：南开大学环境科学与生态学跻身ESI全球前1‰-媒体南开-南开大学.html\n",
      "网页标题: 中宏网：南开大学环境科学与生态学跻身ESI全球前1‰-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2024/07/18/030062657.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\中宏网：南开大学环境科学与生态学跻身ESI全球前1‰-媒体南开-南开大学.html\n",
      "网页标题: 南开大学ESI学科取得双突破-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2020/03/14/030038236.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\南开大学ESI学科取得双突破-南开要闻-南开大学.html\n",
      "网页标题: 我校新增植物与动物科学学科进入ESI全球前1%-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2019/03/27/000439857.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\我校新增植物与动物科学学科进入ESI全球前1%-南开要闻-南开大学.html\n",
      "网页标题: 中国发展网：南开大学ESI全球前1%学科增至11个 分子生物学与遗传学“入列”-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2018/05/18/000383271.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\中国发展网：南开大学ESI全球前1%学科增至11个%20分子生物学与遗传学“入列”-媒体南开-南开大学.html\n",
      "网页标题: 【1367期】学校召开学科建设工作会议-南开大学报-南开大学, 网页链接: http://news.nankai.edu.cn/nkdxb/system/2018/08/08/000404334.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\【1367期】学校召开学科建设工作会议-南开大学报-南开大学.html\n",
      "\n",
      "查询日志：\n",
      "1. 南开大学ESI学科发展报告pdf\n",
      "\n",
      "推荐搜索：\n",
      "被引、南开要闻、进入ESI、环境科学、媒体南开、全球前、南开大学报、ESI全球、南开校史、光影南开\n",
      "\n",
      "正在搜索：南开大学新校区\n",
      "搜索结果：\n",
      "网页标题: 城市快报：南开天大新校区啥模样-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2010/03/10/000029044.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\城市快报：南开天大新校区啥模样-媒体南开-南开大学.html\n",
      "网页标题: 【1208期】薛进文调研新校区建设-南开大学报-南开大学, 网页链接: http://news.nankai.edu.cn/nkdxb/system/2013/10/25/000148444.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\【1208期】薛进文调研新校区建设-南开大学报-南开大学.html\n",
      "网页标题: 【新校区】薛进文调研津南新校区施工现场-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2013/09/26/000142067.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\【新校区】薛进文调研津南新校区施工现场-南开要闻-南开大学.html\n",
      "网页标题: 天津人民广播电台：传承保护并重，南开大学6月中下旬启动搬迁，天南大北洋园新校区9月全面投入使用-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2015/05/20/000235062.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\天津人民广播电台：传承保护并重，南开大学6月中下旬启动搬迁，天南大北洋园新校区9月全面投入使用-媒体南开-南开大学.html\n",
      "网页标题: 城市快报：南开新校区正式启用-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2015/09/06/000246904.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\城市快报：南开新校区正式启用-媒体南开-南开大学.html\n",
      "网页标题: 新华社：南开大学新校区９月新学期投入使用-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2015/08/29/000246315.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\新华社：南开大学新校区９月新学期投入使用-南开要闻-南开大学.html\n",
      "网页标题: 汉院学生寒假社会实践聚焦新校区治理-综合新闻-南开大学, 网页链接: http://news.nankai.edu.cn/zhxw/system/2015/03/09/000224435.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\汉院学生寒假社会实践聚焦新校区治理-综合新闻-南开大学.html\n",
      "网页标题: 每日新报：天大南大这个暑假 “搬新家”(图)-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2015/01/08/000216915.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\每日新报：天大南大这个暑假%20“搬新家”(图)-媒体南开-南开大学.html\n",
      "网页标题: 津南校区通勤公交陆续开通-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2015/09/11/000247774.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\津南校区通勤公交陆续开通-南开要闻-南开大学.html\n",
      "网页标题: 每日新报：海河教育园天南大新校区组团式布局 宿舍有空调-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2013/11/22/000156087.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\每日新报：海河教育园天南大新校区组团式布局%20宿舍有空调-媒体南开-南开大学.html\n",
      "\n",
      "查询日志：\n",
      "1. 南开大学ESI学科发展报告pdf\n",
      "2. 南开大学新校区\n",
      "\n",
      "推荐搜索：\n",
      "校区建设、津南校区、媒体南开、南开要闻、南开大学报、南开校史、光影南开、南开故事、校史网、南开南开\n",
      "\n",
      "正在搜索：新冠肺炎防控指南漫画\n",
      "搜索结果：\n",
      "网页标题: 南开大学教师主译 《新冠肺炎防控指南漫画双语系列》推出-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2020/07/04/030040017.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\南开大学教师主译%20《新冠肺炎防控指南漫画双语系列》推出-南开要闻-南开大学.html\n",
      "网页标题: 持续科研攻关 为打赢疫情防控阻击战贡献南开力量-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2020/03/15/030038251.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\持续科研攻关%20为打赢疫情防控阻击战贡献南开力量-南开要闻-南开大学.html\n",
      "网页标题: 中国科学报：免疫在新冠肺炎发病和治疗中起何作用-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2020/04/27/030038948.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\中国科学报：免疫在新冠肺炎发病和治疗中起何作用-媒体南开-南开大学.html\n",
      "网页标题: 杨树山：因为我爱漫画-多彩校园-南开大学, 网页链接: http://news.nankai.edu.cn/dcxy/system/2014/11/19/000209515.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\杨树山：因为我爱漫画-多彩校园-南开大学.html\n",
      "网页标题: 南开大学与推想科技利用CT影像AI筛查助力新冠肺炎疫情防控-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2020/03/12/030038105.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\南开大学与推想科技利用CT影像AI筛查助力新冠肺炎疫情防控-南开要闻-南开大学.html\n",
      "网页标题: 我校参加全国教育系统疫情防控工作视频会议-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2022/03/15/030050600.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\我校参加全国教育系统疫情防控工作视频会议-南开要闻-南开大学.html\n",
      "网页标题: 光明日报：美国政府应对疫情的“三不”及其带来的人权灾难-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2020/10/22/030041336.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\光明日报：美国政府应对疫情的“三不”及其带来的人权灾难-媒体南开-南开大学.html\n",
      "网页标题: 我校参加教育部秋季学期开学和秋冬季疫情防控工作视频会-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2020/08/31/030040605.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\我校参加教育部秋季学期开学和秋冬季疫情防控工作视频会-南开要闻-南开大学.html\n",
      "网页标题: 学校召开会议部署强化新冠肺炎疫情防控工作-南开要闻-南开大学, 网页链接: http://news.nankai.edu.cn/ywsd/system/2021/08/04/030047483.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\学校召开会议部署强化新冠肺炎疫情防控工作-南开要闻-南开大学.html\n",
      "网页标题: 中国日报网：南开大学与推想科技利用CT影像AI筛查助力新冠肺炎疫情防控-媒体南开-南开大学, 网页链接: http://news.nankai.edu.cn/mtnk/system/2020/03/13/030038233.shtml\n",
      "本地文件链接: file:///d:\\Programs\\InformationRetrieval\\HtmlFile\\中国日报网：南开大学与推想科技利用CT影像AI筛查助力新冠肺炎疫情防控-媒体南开-南开大学.html\n",
      "\n",
      "查询日志：\n",
      "1. 南开大学ESI学科发展报告pdf\n",
      "2. 南开大学新校区\n",
      "3. 新冠肺炎防控指南漫画\n",
      "\n",
      "推荐搜索：\n",
      "新冠肺炎、疫情防控、肺炎疫情、新冠病毒、南开要闻、CT影像、媒体南开、肺炎防控、防控工作、防控指南\n",
      "\n",
      "退出程序。\n"
     ]
    }
   ],
   "source": [
    "# 中文分词\n",
    "def tokenize(text):\n",
    "    return list(jieba.cut(text))\n",
    "\n",
    "# 计算查询的TF-IDF向量\n",
    "def compute_query_tfidf(query, idf):\n",
    "    query_tokens = tokenize(query)\n",
    "    query_tf = defaultdict(int)\n",
    "    \n",
    "    # 计算TF\n",
    "    for word in query_tokens:\n",
    "        query_tf[word] += 1\n",
    "    total_words = len(query_tokens)\n",
    "    for word in query_tf:\n",
    "        query_tf[word] /= total_words\n",
    "    \n",
    "    # 计算TF-IDF\n",
    "    query_tfidf = {}\n",
    "    for word, tf in query_tf.items():\n",
    "        query_tfidf[word] = tf * idf.get(word, 0)  # 默认IDF为0\n",
    "    \n",
    "    return query_tfidf\n",
    "\n",
    "# 计算文档与查询的相关度（余弦相似度）\n",
    "def compute_cosine_similarity(query_tfidf, doc_tfidf):\n",
    "    dot_product = sum(query_tfidf.get(word, 0) * doc_tfidf.get(word, 0) for word in query_tfidf)\n",
    "    query_norm = math.sqrt(sum(val**2 for val in query_tfidf.values()))\n",
    "    doc_norm = math.sqrt(sum(val**2 for val in doc_tfidf.values()))\n",
    "    if query_norm * doc_norm == 0:\n",
    "        return 0\n",
    "    return dot_product / (query_norm * doc_norm)\n",
    "\n",
    "# 执行搜索\n",
    "def search(query, inverted_index, doc_tfs, idf, top_n=10):\n",
    "    print(f\"\\n正在搜索：{query}\")\n",
    "    # 计算查询的TF-IDF向量\n",
    "    query_tfidf = compute_query_tfidf(query, idf)\n",
    "    \n",
    "    # 计算每个文档与查询的相关度\n",
    "    scores = []\n",
    "    for doc_id, doc_tfidf in enumerate(doc_tfs):\n",
    "        score = compute_cosine_similarity(query_tfidf, doc_tfidf)\n",
    "        scores.append((doc_id, score))\n",
    "    \n",
    "    # 按相关度排序并返回前top_n个文档\n",
    "    scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_docs = scores[:top_n]\n",
    "    \n",
    "    return top_docs\n",
    "\n",
    "# 定义循环次数计数器\n",
    "search_count = 0\n",
    "\n",
    "# 初始化查询日志\n",
    "query_log = []\n",
    "\n",
    "# 假设 html 文件存放在当前目录下的 HtmlFile 文件夹\n",
    "html_folder = './HtmlFile/'\n",
    "\n",
    "# 确保 HtmlFile 文件夹存在\n",
    "if not os.path.exists(html_folder):\n",
    "    print(\"HtmlFile 文件夹不存在，请检查文件路径。\")\n",
    "    exit()\n",
    "\n",
    "# 定义一个用于过滤标点符号的函数\n",
    "def is_valid_word(word):\n",
    "    # 判断单词中是否包含特定符号或是否为特定无效单词\n",
    "    invalid_symbols = ['，', '%', '‰', '、']\n",
    "    invalid_words = ['与', '本', '的', '由', '多', '1', '新']\n",
    "    \n",
    "    # 如果单词包含无效符号或者是无效单词，则返回 False\n",
    "    if any(symbol in word for symbol in invalid_symbols) or word in invalid_words:\n",
    "        return False\n",
    "    \n",
    "    # 判断单词中是否包含标点符号\n",
    "    return all(char not in string.punctuation for char in word)\n",
    "\n",
    "# 分词并统计双词\n",
    "def extract_bigrams(text):\n",
    "    words = list(jieba.cut(text))  # 切割文本\n",
    "    bigrams = []\n",
    "    for i in range(len(words) - 1):\n",
    "        # 生成双词组合（bigram）\n",
    "        bigram = f\"{words[i]}{words[i+1]}\"\n",
    "        # 过滤掉包含标点符号的双词\n",
    "        if is_valid_word(words[i]) and is_valid_word(words[i+1]):\n",
    "            bigrams.append(bigram)\n",
    "    return bigrams\n",
    "\n",
    "while True:\n",
    "    # 根据循环次数决定搜索内容\n",
    "    if search_count == 0:\n",
    "        query = \"南开大学ESI学科发展报告pdf\"\n",
    "    elif search_count == 1:\n",
    "        query = \"南开大学新校区\"\n",
    "    elif search_count == 2:\n",
    "        query = \"新冠肺炎防控指南漫画\"\n",
    "    elif search_count == 3:\n",
    "        query = \"exit\"\n",
    "    else:\n",
    "        query = input(\"请输入查询词（输入 'exit' 退出）：\")\n",
    "    \n",
    "    # 如果用户输入 \"exit\"，退出循环\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"\\n退出程序。\")\n",
    "        break\n",
    "    \n",
    "    # 执行搜索（这里假设search是一个已定义的搜索函数）\n",
    "    top_docs = search(query, inverted_index, doc_tfs, idf, top_n=10)\n",
    "    \n",
    "    # 输出搜索结果\n",
    "    print(\"搜索结果：\")\n",
    "    \n",
    "    all_bigrams = []  # 用于收集所有搜索结果中的双词\n",
    "    \n",
    "    for doc_id, score in top_docs:\n",
    "        # 获取网页的 标题 和 URL 和 锚文本 和 正文\n",
    "        webpage_title = html_data[doc_id][0]    # 假设第一列是 标题\n",
    "        webpage_url = html_data[doc_id][1]      # 假设第二列是 URL\n",
    "        webpage_anchors = html_data[doc_id][2]  # 假设第三列是 锚文本\n",
    "        webpage_body = html_data[doc_id][3]     # 假设第四列是 正文\n",
    "\n",
    "        # 收集锚文本和正文中的双词\n",
    "        all_bigrams.extend(extract_bigrams(webpage_anchors))\n",
    "        all_bigrams.extend(extract_bigrams(webpage_body))\n",
    "\n",
    "        # 构建本地文件路径（假设网页标题对应文件名）\n",
    "        local_file_path = os.path.join(html_folder, f\"{webpage_title}.html\")\n",
    "        \n",
    "        # 检查文件是否存在\n",
    "        if os.path.exists(local_file_path):\n",
    "            # 替换文件路径中的空格为 %20\n",
    "            local_file_path = local_file_path.replace(' ', '%20')\n",
    "            \n",
    "            # 构建 file:// 协议的本地路径\n",
    "            local_file_url = f\"file:///{os.path.abspath(local_file_path)}\"\n",
    "            \n",
    "            print(f\"网页标题: {webpage_title}, 网页链接: {webpage_url}\\n本地文件链接: {local_file_url}\")\n",
    "        else:\n",
    "            print(f\"网页标题: {webpage_title}, 网页链接: {webpage_url}\\n本地文件不存在\")\n",
    "    \n",
    "    # 记录查询日志\n",
    "    query_log.append(query)\n",
    "    \n",
    "    # 输出查询日志\n",
    "    print(\"\\n查询日志：\")\n",
    "    for i, log in enumerate(query_log, 1):\n",
    "        print(f\"{i}. {log}\")\n",
    "    \n",
    "    # 统计双词\n",
    "    bigram_counts = Counter(all_bigrams)\n",
    "    common_bigrams = bigram_counts.most_common(10)\n",
    "    print(\"\\n推荐搜索：\")\n",
    "    \n",
    "    # 输出推荐搜索短语，直接使用双词统计的前10个\n",
    "    for i in range(0, len(common_bigrams), 10):\n",
    "        line = \"、\".join([bigram for bigram, _ in common_bigrams[i:i+10]])\n",
    "        print(line)\n",
    "    \n",
    "    # 增加搜索次数计数\n",
    "    search_count += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
